{
  "hash": "a612b96aba92b2b391b30d9426ecfab0",
  "result": {
    "markdown": "---\ntitle: \"13: Knights of the Dinner Table\"\n---\n\n::: {.cell hash='2015-13_cache/html/unnamed-chunk-1_39428f8783d54281aac147c1df7e8b41'}\n\n```{.r .cell-code}\nlibrary(mistlecode)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTo install `mistlecode` yourself, run `devtools::install_github('guslipkin/mistlecode')`.\n\n Also loading:  cipheR data.table dplyr purrr slider stringr tidyverse glue\n```\n:::\n\n```{.r .cell-code}\ndt <- \n  fread(\"input.txt\") |>\n  select(V1, V3, V4, V11) |>\n  `colnames<-`(c(\"origin\", \"direction\", \"units\", \"subject\")) |>\n  mutate(\n    units = ifelse(direction == \"lose\", units * -1, units),\n    subject = str_remove(subject, \"\\\\.\")\n  ) |>\n  select(-direction)\n```\n:::\n\n::: {.cell hash='2015-13_cache/html/unnamed-chunk-2_281396b7809cc98f8988c2c4f672df82'}\n\n```{.r .cell-code}\nsolve <- function(m) {\n  m <- m + t(m)\n  m2 <- 1 / scales::rescale(m)\n  \n  stops <-\n    m2 |>\n    TSP::as.TSP() |>\n    TSP::insert_dummy(label = \"dummy\") |>\n    TSP::solve_TSP(method = \"nn\", control = list(rep = 1000)) |>\n    TSP::cut_tour(\"dummy\") |>\n    names() |>\n    data.frame() |>\n    `colnames<-`(c(\"start\")) |>\n    mutate(end = lead(start),\n           end = ifelse(is.na(end), start[1], end))\n  \n  m |>\n    data.frame() |>\n    rownames_to_column() |>\n    pivot_longer(!c(\"rowname\")) |>\n    filter(!is.na(value)) |>\n    `colnames<-`(c(\"start\", \"end\", \"dist\")) |>\n    right_join(stops, by = c(\"start\", \"end\")) |>\n    pull(dist) |>\n    sum()\n}\n```\n:::\n\n\nAs usual, this was moved into a function after part 1 because I reused it in part 2.\n\n\n## Part 1\n\nHonestly, not a clue.\n\nOkay. I'm back. It's been a few weeks but I had a stroke of inspiration last night. I had started out trying a bunch of longer data and filtering, brute forcing, and anything else I could think of. BUT. Last night I realized this is just a circular traveling salesman problem. After a bit of fiddling with my solution from [2015-09](/2015/09/2015-09.html) I was able to get it. Some key things were rescaling from 0-1 so that I don't have both positive and negative numbers, then using the $\\frac{1}{x}$ trick to get longest distances instead of shortest.\n\n\n::: {.cell hash='2015-13_cache/html/unnamed-chunk-3_12f4129e9a84f907d3ae6a855524f412'}\n\n```{.r .cell-code}\nm <- \n  dt |>\n  dcast(origin ~ subject, value.var = \"units\", fill = 0) |>\n  column_to_rownames(\"origin\") |>\n  as.matrix() |>\n  `diag<-`(NA_integer_)\n\nsolve(m)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: executing %dopar% sequentially: no parallel backend registered\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 618\n```\n:::\n:::\n\n\n## Part 2\n\nI always knew my relationships had a happiness score of zero, but I didn't need to be reminded of it :(.\n\n\n::: {.cell hash='2015-13_cache/html/unnamed-chunk-4_3d4ac7f79f6d379c12a9efc73dca4583'}\n\n```{.r .cell-code}\nm <-\n  dt |>\n  bind_rows(expand.grid(\n    \"origin\" = \"Gus\",\n    \"units\" = 0,\n    \"subject\" = c(\"Gus\", unique(dt$origin))\n  )) |>\n  dcast(origin ~ subject, value.var = \"units\", fill = 0) |>\n  column_to_rownames(\"origin\") |>\n  as.matrix() |>\n  `diag<-`(NA_integer_)\n\nsolve(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 601\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}