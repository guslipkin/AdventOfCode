{
  "hash": "2ee0c39165ccf6b5ba944164e7bdbd2d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"07: No Space Left On Device\"\nformat: html\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mistlecode)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- readLines(\"input.txt\")\nwd <- getwd()\n```\n:::\n\n\n\n\n\nOh no. This will probably use recursion.\n\n## Part 1\n\nMy first attempt I just kinda hoped I wouldn't need recursion. It was silly, but a guy can dream. My next idea was to just create the file system and so that's what I did. Rather than making the files the size it says, I just filled them with one line holding the size so that I could read it in later. Getting the instructions fleshed out wasn't too bad. It reminds me a lot of my [Cat Simulator 2019](https://guslipkin.me/presentations/cat_simulator_2019) project from Intro to UNIX.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndir.create(\"here_we_go\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in dir.create(\"here_we_go\"): 'here_we_go' already exists\n```\n\n\n:::\n\n```{.r .cell-code}\nsetwd(paste0(wd, \"/here_we_go\"))\n\ninvisible(sapply(dt, \\(x) {\n  if(grepl(\"dir \", x)) {\n    d <- str_remove(x, \"dir \")\n    if (!dir.exists(d)) { dir.create(d) }\n  } else if (grepl(\"[0-9]+\", x)) {\n    f <- paste0(str_remove_all(x, \"[0-9 \\\\.]\"), \".txt\")\n    if (!file.exists(f)) {\n      f <- file(f)\n      content <-\n        paste0(as.numeric(paste0(\n          str_extract_all(x, \"\\\\d\", simplify = TRUE), collapse = \"\"\n        )), \"\\n\")\n      cat(content, file = f)\n      close(f)\n    }\n  } else if (grepl(\"\\\\$ cd \\\\.\\\\.\", x)) {\n    setwd(\"../\")\n  } else if (grepl(\"\\\\$ cd \\\\w\", x)) {\n    d <- str_remove(x, \"\\\\$ cd \")\n    if (!dir.exists(d)) { dir.create(d) }\n    setwd(d)\n  } else if (grepl(\"\\\\$ cd /\", x)) {\n    setwd(paste0(wd, \"/here_we_go\")) \n  } else if (!grepl(\"\\\\$ ls|\\\\$ cd /\", x)) { print(x) }\n}))\nsetwd(wd)\n```\n:::\n\n\n\n\n\nGetting this bit working was a pain, but I'm really pleased with it. I had it working on the test input for a while before the real input which was excruciating, but I eventually tracked the problem down to my regex where I remove any file paths. In my earlier step where I repeated file paths then unlisted, any duplicates are assigned a trailing number. In the test input, this number was never more than one digit. In my regex, I was only looking for one digit and so any paths with no digits or more than one digit were missed. With that out of the way, it still doesn't work. Eventually I realized I was collapsing my paths backwards so all my folder sizes were reversed. Fixing that eventually got me where I needed to be.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- \npaste0(\"here_we_go/\", list.files(\"here_we_go\", recursive = TRUE)) |>\n  sapply(\\(x) {\n    count <- str_count(x, \"/\") - 1\n    count <- ifelse(count == 0, 1, count)\n    rep(x, count)\n  }) \npaths <-\n  v |>\n  lapply(\\(x) {\n    xx <- str_remove(x, \"here_we_go/\")\n    sapply(0:(length(x) - 1), \\(x) {\n      if (x == 0) { return(xx) }\n      m <- str_split(xx, \"/\")[[1]]\n      m <- m[-(length(m) - (1:x))]\n      m <- paste0(m, collapse = \"/\")\n      return(m)\n    }) |>\n      unlist() |>\n      unique()\n  }) |>\n  unlist() |>\n  unname()\n\nfiles <- \n  v |>\n  unlist() |>\n  sapply(\\(x) {\n    x <- as.numeric(readLines(x))\n  }) |>\n  data.frame() |>\n  rownames_to_column(var = \"path\") |>\n  `colnames<-`(c(\"full_path\", \"size\")) |>\n  cbind(paths) |>\n  mutate(path = str_remove(paths, \"/\\\\w*\\\\.txt\\\\d*\"))\n  # filter(grepl(\"\\\\.txt\", path)) |>\n  # mutate(path = str_remove(path, \"/\\\\w*\\\\.txt[0-9]?\"))\nfiles |>\n  group_by(path) |>\n    summarise(size = sum(size)) |>\n    arrange(path, .by_group = TRUE) |>\n  ungroup() |>\n  filter(size <= 100000) |>\n  pull(size) |>\n  sum()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1297683\n```\n\n\n:::\n:::\n\n\n\n\n\n## Part 2\n\nThis wasn't too bad. Just took a bit to make the changes needed from part 1. I was briefly stuck when just grouping by path in the second pipeline, but adding the level grouping took care of it and I was good to go!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- \n  files |>\n  select(paths, size) |>\n  mutate(path = str_remove(paths, \"/\\\\w*\\\\.txt\\\\d*\")) |>\n  select(-paths) |>\n  unique() |>\n  group_by(path) |>\n    summarise(size = sum(size)) |>\n    ungroup() |>\n  mutate(level = str_count(path, \"/\"))\nhome <- sum(f$size[f$level == 0])\n\nf |>\n  group_by(path, level) |>\n    summarise(size = sum(size), .groups = \"keep\") |>\n    arrange(path, .by_group = TRUE) |>\n    ungroup() |>\n  mutate(free = 70000000 - home,\n         sort = size + free) |>\n  arrange(desc(sort), size) |>\n  filter(sort > 30000000) |>\n  tail(1) |>\n  pull(size)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5756764\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}